misclass(trainSA$chd,predictiontrain)
missclass(trainSA$chd,predictiontrain)
missclass(testSA$chd,predictiontest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
names(vowel.train)
head(vowel.train)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
names(vowel.train)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train <- tranform(vowel.train, y=factor(y))
vowel.test <- tranform(vowel.test, y=factor(y))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train <- transform(vowel.train, y=factor(y))
vowel.test <- transform(vowel.test, y=factor(y))
sapply(vowel.train,class)
set.seed(33833)
?varImp
varImp(modelFit)
varImp(modelfit)
set.seed(33833)
modelfit<- train(y~.,method="rf",data=vowel.train)
set.seed(33833)
modelfit<- train(y~.,method="rf",data=vowel.train)
varImp(modelfit)
library(pgmm)
data(olive)
olive=olive[,-1]
head(plive)
head(olive)
nrow(olive)
unique(area)
unique(Area)
unique(olive$Area)
modelfit<-train(Area~.,method="rpart",data=olive)
newdata= as.data.frame(t(colMeans(olive)))
head(newdata)
colMeans(olive)
?t
t(colMeans(olive))
library(pgmm)
data(olive)
olive=olive[,-1]
modelfit<-train(Area~.,method="rpart",data=olive)
newdata= as.data.frame(t(colMeans(olive)))
predict(modelfit,newdata[,-1])
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
vowel.train <- transform(vowel.train, y=factor(y))
vowel.test <- transform(vowel.test, y=factor(y))
set.seed(33833)
modelfit1=train(y~.,method="rf",data=vowel.train)
modelfit2=train(y~.,method="gbm",data=vowel.train)
set.seed(33833)
modelfit1=train(y~.,method="rf",data=vowel.train)
modelfit2=train(y~.,method="gbm",data=vowel.train)
pred1=prediction(modelfit1,vowel.test)
pred2=prediction(modelfit2,vowel.test)
set.seed(33833)
modelfit1=train(y~.,method="rf",data=vowel.train)
modelfit2=train(y~.,method="gbm",data=vowel.train)
pred1=prediction(modelfit1,vowel.test[,-1])
pred2=prediction(modelfit2,vowel.test[,-1])
set.seed(33833)
modelfit1=train(y~.,method="rf",data=vowel.train)
modelfit2=train(y~.,method="gbm",data=vowel.train)
set.seed(33833)
modelfit1=train(y~.,method="rf",data=vowel.train)
modelfit2=train(y~.,method="gbm",data=vowel.train,verbose=FALSE)
pred1=predict(modelfit1,vowel.test[,-1])
pred2=predict(modelfit2,vowel.test[,-1])
confusionMatrix(vowel.test$y,pred1)
confusionMatrix(vowel.test$y,pred2)
install.packages("aggrement")
aggrement(pred1,pred2)
library(aggrement)
install.packages("Agreement")
Agreement(pred1,pred2)
library(Agreement)
Agreement(pred1,pred2)
agreement(pred1,pred2)
?aggrement
agreement(pred1,pred2,error="const")
confusionMatrix(pred1,pred2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelfit1=train(diagnosis~.,method="rf",data=training)
modelfit2=train(diagnosis~.,method="gbm",data=training,vebose=FALSE)
modelfit3=train(diagnosis~.,method="lda",data=training)
pred1=predict(modelfit1,testing[,-1])
pred2=predict(modelfit2,testing[,-1])
pred3=predict(modelfit3,testing[,-1])
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelfit1=train(diagnosis~.,method="rf",data=training)
modelfit2=train(diagnosis~.,method="gbm",data=training,vebose=FALSE)
modelfit3=train(diagnosis~.,method="lda",data=training)
pred1=predict(modelfit1,testing[,-1])
pred2=predict(modelfit2,testing[,-1])
pred3=predict(modelfit3,testing[,-1])
library(rf)
modelfit2=train(diagnosis~.,method="gbm",data=training,vebose=FALSE)
modelfit2=train(diagnosis~.,method="gbm",data=training)
modelfit2=train(diagnosis~.,method="gbm",data=training,vebose=FALSE)
set.seed(62433)
modelfit2=train(diagnosis~.,method="gbm",data=training,vebose=FALSE)
modelfit3=train(diagnosis~.,method="lda",data=training)
pred3=predict(modelfit3,testing[,-1])
modelfit2=train(diagnosis~.,method="gbm",data=training,verbose=FALSE)
pred1=predict(modelfit1,testing[,-1])
pred2=predict(modelfit2,testing[,-1])
predDF=data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combmodfit=train(diagnosis~.,method="rf",data=predDF)
combpred=predict(combmodfit,predDF)
sqrt(sum((combpred - testing$diagnosis)^2))
confusionMatrix(combpred,testing$diagnosis)
confusionMatrix(pred1,testing$diagnosis)
confusionMatrix(pred2,testing$diagnosis)
confusionMatrix(pred3,testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
names(training)
CompressiveStrength
set.seed(233)
modelfit=train(CompressiveStrength~.,method="lasso",data=training)
set.seed(233)
modelfit=train(CompressiveStrength~.,method="lasso",data=training)
?plot.enet
plot.enet(modelfit,xvar=c("penalty"))
plot.enet(modelfit,xvar="penalty")
summary(modelfit)
plot.enet(modelfit,xvar="penalty")
?enet
modelfit=enet(x=trainig[,-9],y=training[,9],lambda=0)
modelfit=enet(x=training[,-9],y=training[,9],lambda=0)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
plot(modelfit)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
getwd()
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=1)
plot(modelfit)
install.packages("e1071")
?svm
??svm
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
names(training)
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modelfit=svm(CompressiveStrength~.,data=training)
pred1=predict(modelfit,training)
confusionMatrix(pred1,training$CompressiveStregth)
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modelfit=svm(CompressiveStrength~.,data=training)
pred1=predict(modelfit,testing)
confusionMatrix(pred1,testing$CompressiveStregth)
names(testing)
confusionMatrix(pred1,testing$CompressiveStrength)
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modelfit=svm(CompressiveStrength~.,data=training)
pred1=predict(modelfit,testing[,-9])
confusionMatrix(pred1,testing$CompressiveStregth)
nrow(pred1)
names(testing)
summary(modelfit)
head(testing[,-9])
pred1=predict(modelfit,testing[,-9])
nrow(pred1)
pred1
nrow(testing)
table(pred1,testing$CompressiveStregth)
pred1=t(predict(modelfit,testing[,-9]))
table(pred1,testing$CompressiveStregth)
pred1=as.data.frame(predict(modelfit,testing[,-9])))
pred1=as.data.frame(predict(modelfit,testing[,-9]))
pred1=as.data.frame(predict(modelfit,testing[,-9])))
confusionMatrix(pred1,testing$CompressiveStregth)
pred1=as.data.frame(predict(modelfit,testing[,-9]))
confusionMatrix(pred1,testing$CompressiveStregth)
confusionMatrix(pred1,as.data.frame(testing$CompressiveStregth))
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modelfit=svm(CompressiveStrength~.,data=training)
pred1=as.data.frame(predict(modelfit,testing[,-9]))
pred1
confusionMatrix(pred1,as.data.frame(testing$CompressiveStregth))
pred1=predict(modelfit,testing[,-9])
confusionMatrix(pred1,testing$CompressiveStregth)
testing$CompressiveStregth
name(testing)
names(testing)
testing$CompressiveStrength
confusionMatrix(pred1,testing$CompressiveStrength)
length(pred1)
pred1=predict(modelfit,testing)
pred1
head(testing)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelfit1=train(diagnosis~.,method="rf",data=training)
modelfit2=train(diagnosis~.,method="gbm",data=training,verbose=FALSE)
modelfit3=train(diagnosis~.,method="lda",data=training)
pred1=predict(modelfit1,testing[,-1])
pred2=predict(modelfit2,testing[,-1])
pred3=predict(modelfit3,testing[,-1])
pred1
head(testing)
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modelfit=svm(CompressiveStrength~.,data=training)
pred1=predict(modelfit,testing)
confusionMatrix(pred1,testing$CompressiveStrength)
sqrt(sum((pred1-testing$CompressiveStrength)^2))
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
modelfit=svm(CompressiveStrength~.,data=training)
pred1=predict(modelfit,testing)
sqrt(sum((pred1-testing$CompressiveStrength)^2))
sqrt(sum((pred1-testing$CompressiveStrength)^2))/length(pred1)
rmse(pred1,testing$CompressiveStrength)
sqrt(mean((pred1-testing$CompressiveStrength)^2))
confusionMatrix(testing$CompressiveStrength,pred1)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats()
?bats
??bats
install.packages("BAT")
?bats
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
modeflfit=bats(testing)
library(BATS)
library(BAT)
modeflfit=bats(testing)
install.packages("forecast")
modeflfit=bats(testing)
library(forecast)
modeflfit=bats(testing)
modeflfit= bats(tstrain)
pred=predict(modelfit,tstest)
tstest = ts(training$visitsTumblr)
pred=predict(modelfit,tstest)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(training$visitsTumblr)
library(forecast)
modeflfit= bats(tstrain)
pred=predict(modelfit,tstest)
pred=forecast(modelfit,tstest)
?forecast
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(training$visitsTumblr)
library(forecast)
modeflfittrain= bats(tstrain)
modeflfittest= bats(tstest)
pred=forecast(modeflfittest)
accuracy(pred,tstest)
pred1
fcast=forecast(modeflfittest)
accuracy(fcast,tstest)
confusionMatrix(fcast,tstest)
modeflfittrain= bats(tstrain)
modeflfittest= bats(tstest)
fcast=forecast(modeflfittest)
confusionMatrix(fcast,tstest)
?confusionMatrix
?accuracy
accuracy(fcast,tstest)
tstest
fcast
accuracy(fcast,tstest)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelfit1=train(diagnosis~.,method="rf",data=training)
modelfit2=train(diagnosis~.,method="gbm",data=training,verbose=FALSE)
modelfit3=train(diagnosis~.,method="lda",data=training)
pred1=predict(modelfit1,testing[,-1])
pred2=predict(modelfit2,testing[,-1])
pred3=predict(modelfit3,testing[,-1])
predDF=data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combmodfit=train(diagnosis~.,method="rf",data=predDF)
combpred=predict(combmodfit,predDF)
confusionMatrix(combpred,testing$diagnosis)
confusionMatrix(pred1,testing$diagnosis)
confusionMatrix(pred2,testing$diagnosis)
confusionMatrix(pred3,testing$diagnosis)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(training$visitsTumblr)
library(forecast)
modeflfittrain= bats(tstrain)
modeflfittest= bats(tstest)
fcast=forecast(modeflfittest)
length(tstrain)
length(tstest)
class(fcast)
dim(fcast)
fcast
fcast=forecast(modeflfittrain)
fcast
fcast$fitted
confusionMatrix(fcast$fitted,tstest)
tstest
modeflfittest= bats(tstest)
?forecats
?forecast
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
set.seed(3523)
library(AppliedPredictiveModeling)
library(enet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
?enet
??enet
library(elasticnet)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
plot.enet(modelfit)
?plot.enet
?plot.enet
library(AppliedPredictiveModeling)
library(elasticnet)
library(enet)
library(caret)
?plot.enet
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
summary(modelfit)
modelfit
enet
?enet
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
names(training)
setwd("/Users/malaydas/Documents/Data Science/Developing Data Products/Programing Assignment")
shiny::runApp('Data Product Assignment1')
---
title       : Predicting children Height
library(slidify)
getwd()
author("Data Product Assignment2")
